---
title: "Merging route networks"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Merging route networks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  # # Uncomment to speed-up build
  eval = FALSE,
  comment = "#>",
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)
devtools::load_all()
sf::sf_use_s2(FALSE)
```

```{r setup}
library(stplanr)
library(dplyr)
library(tmap)
rnet_x = sf::read_sf("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_x_ed.geojson")
rnet_y = sf::read_sf("https://github.com/ropensci/stplanr/releases/download/v1.0.2/rnet_y_ed.geojson")
# dups = duplicated(rnet_x$geometry)
# summary(dups)
# rnet_x = rnet_x |>
#   filter(!dups)
# sf::write_sf(rnet_x, "~/github/ropensci/stplanr/rnet_x_ed.geojson", delete_dsn = TRUE)
```

# Target network preprocessing

We pre-processed the input simple geometry to make it even simpler as shown below.

```{r, out.width="50%", fig.width=8, fig.height=6, fig.show='hold'}
# tmap_mode("view")
# nrow(rnet_x)
# summary(sf::st_length(rnet_x))
plot(sf::st_geometry(rnet_x))
rnet_x = rnet_subset(rnet_x, rnet_y, dist = 20)
# nrow(rnet_x)
# plot(sf::st_geometry(rnet_x))
rnet_x = rnet_subset(rnet_x, rnet_y, dist = 20, min_length = 5)
# summary(sf::st_length(rnet_x))
# nrow(rnet_x)
# plot(sf::st_geometry(rnet_x))
rnet_x = rnet_subset(rnet_x, rnet_y, dist = 20, rm_disconnected = TRUE)
# nrow(rnet_x)
plot(sf::st_geometry(rnet_x))
```

The initial merged result was as follows (original data on left)

```{r}
funs = list(value = sum, Quietness = mean)
brks = c(0, 100, 500, 1000, 5000)
rnet_merged = rnet_merge(rnet_x, rnet_y, dist = 10, segment_length = 20, funs = funs)
m1 = tm_shape(rnet_y) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)  +
  tm_scale_bar()
m2 = tm_shape(rnet_merged) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)
tmap_arrange(m1, m2, sync = TRUE, nrow = 1)
```

Let's check the results:

```{r}
summary(rnet_merged$value)
summary(rnet_y$value)
sum(rnet_merged$value * sf::st_length(rnet_merged), na.rm = TRUE)
sum(rnet_y$value * sf::st_length(rnet_y), na.rm = TRUE)
```

We can more reduce the minimum segment length to ensure fewer NA values in the outputs:

```{r}
rnet_merged = rnet_merge(rnet_x, rnet_y, dist = 20, segment_length = 10, funs = funs)
m1 = tm_shape(rnet_y) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)
m2 = tm_shape(rnet_merged) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)
tmap_arrange(m1, m2, sync = TRUE, nrow = 1)
```

As shown in the results, some sideroad values have unrealistically high values:

![](https://user-images.githubusercontent.com/1825120/267946945-d89dfb99-fb60-4db5-ab39-168773ef01ad.png)

Let's see the results again:

```{r}
summary(rnet_merged$value)
summary(rnet_y$value)
sum(rnet_merged$value * sf::st_length(rnet_merged), na.rm = TRUE)
sum(rnet_y$value * sf::st_length(rnet_y), na.rm = TRUE)
```

The good news: the number of NAs is down to only 21 compared with the previous 100+.
Bad news: sideroads have been assigned values from the main roads.

We can fix this with the `max_angle_diff` argument:

```{r}
rnet_merged = rnet_merge(rnet_x, rnet_y, dist = 20, segment_length = 10, funs = funs, max_angle_diff = 40)
m1 = tm_shape(rnet_y) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)
m2 = tm_shape(rnet_merged) + tm_lines("value", palette = "viridis", lwd = 5, breaks = brks)
tmap_arrange(m1, m2, sync = TRUE, nrow = 1)
```

As shown in the results, the sideroad values are fixed:

![](https://user-images.githubusercontent.com/1825120/267955054-3bd393a7-1fdd-44a4-8717-7933199c6f37.png)

Let's see the results again:

```{r}
summary(rnet_merged$value)
summary(rnet_y$value)
sum(rnet_merged$value * sf::st_length(rnet_merged), na.rm = TRUE)
sum(rnet_y$value * sf::st_length(rnet_y), na.rm = TRUE)
```

Now let's testing on 3km dataset

```{r setup}
rnet_x = sf::read_sf("https://github.com/nptscot/networkmerge/releases/download/v0.1/os_3km.geojson")
rnet_y = sf::read_sf("https://github.com/nptscot/npt/releases/download/rnet_3km_buffer/rnet_3km_buffer.geojson")
```

```{r}
# Extract column names from the rnet_x data frame
name_list <- names(rnet_y)
name_list
# Initialize an empty list
funs <- list()

# Loop through each name and assign it a function based on specific conditions
for (name in name_list) {
  if (name == "geometry") {
    next  # Skip the current iteration
  } else if (name %in% c("Gradient", "Quietness")) {
    funs[[name]] <- mean
  } else {
    funs[[name]] <- sum
  }
}
names(rnet_x)
```

```{r}
funs = list(
    all_fastest_bicycle = sum, 
    # all_fastest_bicycle_ebike = sum, 
    # all_fastest_bicycle_go_dutch = sum, 
    all_quietest_bicycle = sum, 
    # all_quietest_bicycle_ebike = sum, 
    # all_quietest_bicycle_go_dutch = sum, 
    commute_fastest_bicycle = sum, 
    # commute_fastest_bicycle_ebike = sum, 
    # commute_fastest_bicycle_go_dutch = sum, 
    commute_quietest_bicycle = sum, 
    # commute_quietest_bicycle_ebike = sum, 
    # commute_quietest_bicycle_go_dutch = sum, 
    primary_fastest_bicycle = sum, 
    # primary_fastest_bicycle_ebike = sum, 
    # primary_fastest_bicycle_go_dutch = sum, 
    primary_quietest_bicycle = sum, 
    # primary_quietest_bicycle_ebike = sum, 
    # primary_quietest_bicycle_go_dutch = sum, 
    secondary_fastest_bicycle = sum, 
    # secondary_fastest_bicycle_ebike = sum, 
    # secondary_fastest_bicycle_go_dutch = sum, 
    secondary_quietest_bicycle = sum, 
    # secondary_quietest_bicycle_ebike = sum, 
    # secondary_quietest_bicycle_go_dutch = sum, 
    Gradient = mean, 
    Quietness = mean
)
```


all_fastest_bicycleall_fastest_bicycle_ebikeall_fastest_bicycle_go_dutchall_quietest_bicycleall_quietest_bicycle_ebikeall_quietest_bicycle_go_dutchcommute_fastest_bicyclecommute_fastest_bicycle_ebikecommute_fastest_bicycle_go_dutchcommute_quietest_bicyclecommute_quietest_bicycle_ebikecommute_quietest_bicycle_go_dutchprimary_fastest_bicycleprimary_fastest_bicycle_ebikeprimary_fastest_bicycle_go_dutchprimary_quietest_bicycleprimary_quietest_bicycle_ebikeprimary_quietest_bicycle_go_dutchsecondary_fastest_bicyclesecondary_fastest_bicycle_ebikesecondary_fastest_bicycle_go_dutchsecondary_quietest_bicyclesecondary_quietest_bicycle_ebikesecondary_quietest_bicycle_go_dutchGradientQuietnessgeometry
```{r,ev}
brks = c(0, 100, 500, 1000, 5000,10000)
rnet_merged = rnet_merge(rnet_x, rnet_y, dist = 20, segment_length = 10, funs = funs, max_angle_diff = 20)
# st_write(rnet_merged, "data/3km_exmaple.geojson", driver = "GeoJSON")
rnet_merged <- st_make_valid(rnet_merged)
m1 = tm_shape(rnet_y) + tm_lines("all_fastest_bicycle", palette = "viridis", lwd = 5, breaks = brks)
m2 = tm_shape(rnet_merged) + tm_lines("all_fastest_bicycle", palette = "viridis", lwd = 5, breaks = brks)
tmap_arrange(m1, m2, sync = TRUE, nrow = 1)

library(tmaptools)

arranged_map = tmap_arrange(m1, m2, sync = TRUE, nrow = 1)
tmap_save(arranged_map, filename = "3km_exmaple.html")

names(rnet_merged)

summary(rnet_merged$secondary_quietest_bicycle)
summary(rnet_y$secondary_quietest_bicycle)
```

```{r}
rnet_merge <- function(rnet_x, rnet_y, dist = 5, funs = NULL, sum_flows = TRUE, ...) {



sum_cols = sapply(funs, function(f) identical(f, sum))
sum_cols = names(funs)[which(sum_cols)]
sum_cols
rnetj = rnet_join(rnet_x, rnet_y, dist = 20)
names(rnetj)
rnetj_df = sf::st_drop_geometry(rnetj)

# Apply functions to columns with lapply:
sum_flows = TRUE
names(rnet_y)
i = 1
nm = names(funs[i])
fn = funs[[i]]
nm
if (identical(fn, sum) && sum_flows) {
  print("fn match sum")
  print(nm)
  res = rnetj_df %>%
    dplyr::group_by_at(1) %>%
    dplyr::summarise(dplyr::across(dplyr::all_of(nm), function(x) sum(x * length_y)))
} else {
  print("fn don't match sum")
  print(nm)
  res = rnetj_df %>%
    dplyr::group_by_at(1) %>%
    dplyr::summarise(dplyr::across(dplyr::all_of(nm), fn))
}
names(res)
rnetj_df %>%
    dplyr::group_by_at(1) %>%
    dplyr::summarise(dplyr::across(dplyr::matches(nm), fn))
names(rnetj_df)
  names(res)[2] = nm
  if(i > 1) {
    res = res[-1]
  }
  res
})
res_df = dplyr::bind_cols(res_list)

res_sf = dplyr::left_join(rnet_x, res_df)
if (sum_flows) {
  res_sf$length_x = as.numeric(sf::st_length(res_sf))
  for(i in sum_cols) {
    # TODO: deduplicate
    length_y = as.numeric(sf::st_length(rnet_y))
    # i = sum_cols[1]
    res_sf[[i]] = res_sf[[i]] / res_sf$length_x
    over_estimate = sum(res_sf[[i]] * res_sf$length_x, na.rm = TRUE) /
      sum(rnet_y[[i]] * length_y, na.rm = TRUE)
    res_sf[[i]] = res_sf[[i]] / over_estimate
  }
}
```